---
title: "Data Preparation"
output: 
  rmarkdown::html_vignette:
    number_sections: true
vignette: >
  %\VignetteIndexEntry{Data Preparation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This tutorial is on pre-processing for non-accelerometer data. Pre-processing is an important part of the project pipeline – we hope this will give you a lot of flexibility e.g. to decide what variables you want to work with. 
This tutorial contains: 

1.  Troubleshooting
2.	Introduction to available data
3.	Processing covariate data
4.	Processing health outcomes data
5.	Merging data files
6.  Participant withdrawals
7.  Exclusions
8.  Preprocessing
9. 	Finding out more 

# Troubleshooting 
If nothing is working, speak to Rosemary – rosemary.walmsley@gtc.ox.ac.uk. If needed, we have pre-processed data you can use.

# Introduction to available data
Different files are available from UK Biobank for different data types. We will use these files, available under `/cdtshared/wearables/health_data_files`: 

-	`ukb41733.csv`: A ‘standard’ dataset, with one line per participant. It contains most ‘straightforward’ data e.g. sex,  BMI, smoking status etc.
-	`hesin_all.csv`: Hospital Episode Statistics data. Each line is associated with an in-hospital diagnosis. 
-	`death.txt`: Death register data. This has one line per entry in the death register (almost always one line per participant who died), giving their date of death.
- `death_cause.txt`: Death register data on cause of death (multi-line per participant). 
- `withdrawals.csv`: List of participants who have withdrawn from UK Biobank.
-	`accelerometer-basic.csv`: A basic accelerometer dataset. Hopefully you will have your own version, as prepared last week. 
- `dataset-partially-processed`: A partially processed dataset, for this tutorial. 
- `dataset-with-preprocessing-done.csv`: A dataset with the steps in this tutorial (roughly) already performed, for use in the next tutorial if needed.
- `ukb41733.enc_ukb`: A copy of all UK Biobank fields from the main dataset (i.e. not accelerometry, health data etc). Not needed for a basic analysis - see further info below. 

Data should not ever be downloaded to your local machine. All data should be deleted at the end of the Data Challenge. 

The next session uses Python scripts. To ensure you have the appropriate dependencies, run:
```{r, engine='bash', eval = FALSE}
conda activate wearables
```
If you later want to  use RMarkdown, you might have to run: `conda deactivate`. 

# Processing covariate data
This section aims to give you an idea of how to process UK Biobank data from scratch, and to allow you to flexibly go back and consider the variables you want to use (among those available in the [UK Biobank Data Showcase](https://biobank.ndph.ox.ac.uk/ukb/)). However, we have already done the steps here and saved the files for you, so you don't need to redo this. 

Data from UK Biobank comes in a `.enc_ukb` file, from which particular variables are extracted. Once you have an extracted `.csv` file both the column names and the variable codings need processing.

Different tools are available to help with this. We're using a repo that Shing and Rosemary have developed to get going quickly. [Read the docs](https://ukb-download-and-prep-template.readthedocs.io/en/latest/started.html) and [find it on GitHub]( https://ukb-download-and-prep-template.readthedocs.io/en/latest/download.html#downloading-participant-data).
There are usually three key steps: 

- [Installation](https://ukb-download-and-prep-template.readthedocs.io/en/latest/started.html#installation)
-	[Extracting a .csv file from the .enc_ukb file](https://ukb-download-and-prep-template.readthedocs.io/en/latest/download.html#extracting-participant-data-to-csv) (don't do this until you've read on!)
-	[Automated pre-processing of all variables]( https://ukb-download-and-prep-template.readthedocs.io/en/latest/core.html#relabelling-and-recoding-participant-data)

We've done step 2 using a generic (and large!) set of analysis variables, corresponding to those in `analysisCols.txt` in the above repo, and saved the output as `ukb41733.csv`. If you need other variables, feel free to go back and try step 2 - the `ukb41733.enc_ukb` file is available for this purpose. You will need to copy it to another folder to work with it (as the processing file needs to write to the folder it is in) and also change the permissions on `ukbconv` so it is executable (`chmod u+x ukbconv`). 

We've also done step 3 with the same set of columns: this is `dataset-partially-processed.csv` (which has also had some health data added). If you go back and do step 2 you'll have to do step 3 too. You might also jump in at step 3 if you want instances and array indices other than the first measurement at baseline assessment (see next paragraph). 

You can often use this preprocessing pipeline in a fairly blind way. However, *a word of caution*: variables in UK Biobank come with instances and array indices. In the csv file before processing, they are named as fieldnumber.instance.array_index (e.g. 2443.1.0 for the first item ("0") at the first repeat visit ("1")). Repeat 1 was a resurvey among a limited number of participants, repeat 2 is the imaging revisit. Both apply only to a subset of participants. More importantly, some variables have multiple items, as participants could check multiple boxes (e.g. [6138](https://biobank.ndph.ox.ac.uk/ukb/field.cgi?id=6138) on qualifications) or had multiple measures taken (e.g. blood pressure measurements) In these cases, you'll have to [change the defaults](https://ukb-download-and-prep-template.readthedocs.io/en/latest/advanced.html) to usefully use the variables. 

Finding this hard to use? Spotted a bug? We’d love to get feedback and to make it as user-friendly as possible.

# Processing health outcomes data 
This section describes health outcome data. For this section, you can use `dataset-partially-processed.csv` (or your own output from the last section). `dataset-partially-processed.csv` has already had a lot of health outcomes added (corresponding to those in `icdGroups.json` in the above repo), but you are likely to want to add more. 

To do so, follow [these steps](https://ukb-download-and-prep-template.readthedocs.io/en/latest/core.html#adding-hospital-episode-statistics), which describes working with Hospital Episode Statistics (`hesin_all.csv`).

You will probably also want to use data on deaths, which can be found in the `death.txt` and `death_cause.txt` files. Even if mortality is not your outcome, if you are doing analyses of survival data, participants are censored at death for other outcomes. Also, sometimes a disease event may appear in the death register without appearing in Hospital Episode Statistics e.g. a fatal stroke occurring outside of hospital would be recorded on the death register but not in HES. 

Censoring dates for all outcome data are the most recent (as of 17.03.2021!) available in the Data Portal (https://biobank.ctsu.ox.ac.uk/crystal/exinfo.cgi?src=Data_providers_and_dates) i.e. 31/12/20 for the death register; 31/12/20 for HES in England and Scotland, 28/02/18 for HES in Wales.

# Merging data files
You can merge data files using the ‘eid’ column. 
Note that with accelerometer data, the ‘eid’ column may need adjusting to remove extra text e.g. 
```{r, eval = FALSE}
# First we'll load data.table, a package that makes reading large files easier
if (!require("data.table")) install.packages("data.table")
library(data.table)

# Then we load acc data and covariate data
acc <- data.frame(fread("/cdtshared/wearables/health_data_files/accelerometer-basic.csv"))
df <- data.frame(fread("/cdtshared/wearables/health_data_files/dataset-partially-processed.csv"))

# Then we relabel eids to same format
acc$eid <- gsub("_90001_0_0.gz", "", acc$eid) # This line replaces the first string with the second one wherever it appears in acc$eid

# Then we merge
df <- merge(df, acc, by = "eid")
```

# Withdrawals 
Participants have the right to withdraw at any time from UK Biobank. For participants who withdrew between the dataset being generated and it being used, we need to withdraw them manually. 
```{r, eval = FALSE}
nrow(df)
w <- read.csv("/cdtshared/wearables/health_data_files/withdrawals.csv", header = FALSE)
df <- df[!(df$eid %in% w$V1),  ]
nrow(df)
```

# Exclusions 
Before working with the data, we usually exclude some participants. 

First, we exclude participants with poor quality accelerometer data. A standard protocol for exclusions in UK Biobank is to: 

- Exclude participants whose device could not be calibrated: 
```{r, eval = FALSE}
df <- df[df$quality.goodCalibration ==1, ]
```
- Exclude participants who had <3 days wear or did not have wear in each hour of the 24 hour day: 
```{r, eval = FALSE}
df <- df[df$quality.goodWearTime == 1, ]
```
- Exclude participants for whom >1% of values were clipped (fell outside the sensor's range) before or after calibration: 
```{r, eval = FALSE}
df <- df[(df$clipsBeforeCalibration < 0.01*df$totalReads) & (df$clipsAfterCalibration <0.01*df$totalReads) , ]
```
- Exclude participants with unrealistically high average acceleration values: 
```{r, eval = FALSE}
df <- df[df$acc.overall.avg < 100, ]
```

If you're interested in finding out more [this is a good reference](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0169649). There is a lot of literature on accelerometer data quality! 

There are two other types of exclusions you may wish to make, depending on your planned analysis. These can be done now, or later:

- Health-related exclusions. For example, if you are analysing incident disease, you may wish to exclude people who had prevalent disease at the time they wore the accelerometer. 
- Missing covariate data. If small numbers of participants have missing data in covariates, you may wish to exclude them. (Alternatively, you could look into missing data imputation). 

*Important:* You should record how many participants were excluded at each of the above steps. 

# Preprocessing 

As described above the data has had some rough preprocessing already performed, corresponding to use of the UK Biobank data dictionary to recode variables.
However, this is automated and imperfect. For example, some numeric variables may have special values indicating missing data, which have not been automatically processed (an example is [fresh fruit intake](https://biobank.ndph.ox.ac.uk/showcase/field.cgi?id=1309)).

Now is a good time to look at the variables you're planning to use in more detail, understand their distribution, recode any values you wish to recode, and change groupings as required. For example, the [ethnicity variable](https://biobank.ndph.ox.ac.uk/showcase/field.cgi?id=21000) has many distinctions, some of which apply to very few participants, so you may wish to recode it for statistical analyses. Spending time understanding the data in detail now will not be wasted!

One thing you will need to do is add an age-at-accelerometer-wear variable. Here's an example of some code to do that:
```{r, eval = FALSE}
# ADD DATE OF BIRTH
df$approx_dob <-
  as.Date(paste(df$YearOfBirth, df$MonthOfBirth, "15", sep = "-"),
          "%Y-%B-%d")

df$age_entry_days <-
  difftime(as.Date(df$EndTimWear, "%Y-%m-%d %H:%M:%S", tz = "Europe/London"), 
           df$approx_dob,
           units = "days")

df$age_entry_years <- as.numeric(df$age_entry_days)/365.25
df$broadAgeGroup <- cut(df$age_entry_years, breaks = c(40, 50, 60, 70, 80 ), right = FALSE, labels = c("40-49", "50-59", "60-69", "70-79"))

```

If you're interested in incident disease analyses, you might also want to add a follow-up time variable i.e. the difference between the time the participant entered the study (accelerometer wear date) and when they left it: death, censoring (end date of study data, at which point they had not had an event) or the event of interest. The next tutorial contains an example.

The [UK Biobank Data Showcase](https://biobank.ndph.ox.ac.uk/showcase/search.cgi) is the go-to resource for understanding variables in the data.

Remember to write your prepared dataset to a file so that you can use it again!! 

# Finding out more

To find out more about particular UK Biobank variables, use the [Data Showcase](https://biobank.ndph.ox.ac.uk/ukb/)

To find out more about UK Biobank data collection and history, [this](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1001779) is a good summary

In addition to what we’ve shared here, UK Biobank is an open resource and several other open-source tools are available to support its use ([an example](https://git.fmrib.ox.ac.uk/fsl/funpack))

In the future, UK Biobank will be moving to an [Amazon Web Services model](https://www.ukbiobank.ac.uk/learn-more-about-uk-biobank/news/uk-biobank-creates-cloud-based-health-data-analysis-platform-to-unleash-the-imaginations-of-the-world-s-best-scientific-minds).
